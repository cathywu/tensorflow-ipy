{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "This notebook is from created from the TensorFlow tutorial:\n",
    "http://tensorflow.org/tutorials/mnist/pros/index.md"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the MNIST Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get size of training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "55000"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist.train.num_examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get size of test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist.test.num_examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display size of training images tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(55000, 784)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist.train.images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(55000, 10)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist.train.labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "%pylab inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "first_image_array = mnist.train.images[0, ]\n",
    "image_length = int(np.sqrt(first_image_array.size))\n",
    "first_image = np.reshape(first_image_array, (-1, image_length))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28, 28)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP4AAAD8CAYAAABXXhlaAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAIABJREFUeJztfV2IbNl13rerq6u7uqu7b8/c6A7MxOMEPwuREL0oYBkb\nI4JBwQ+KkAmSHYQfrMTgPEjWy0DIg6UHgWLwiyILyVj4DxTJL45kggkyOJ44UiLFkmUII1u25kpI\nc2/XX3f99M5D9zr3O6vWPudUd3XV6Trrg83Zdbqr6lTV+fZae/2GGCMcDkez0Nr0BTgcjvXDie9w\nNBBOfIejgXDiOxwNhBPf4WggnPgORwNxK+KHEN4RQvhmCOFbIYQPruqiHA7H3SLc1I8fQmgB+BaA\nnwTw9wBeBfDuGOM31f95oIDDsSHEGIN1/jYS/60A/jrG+O0Y4xTA7wB45y1ez+FwrAm3If6LAP6W\nHn/n+pzD4ag53LjncDQQtyH+3wH4EXr80vU5h8NRc9yG+K8C+LEQwsshhA6AdwP4wmouy+Fw3CXa\nN31ijHEeQvgAgC/iagH5ZIzxGyu7MofDcWe4sTuv8hu4O8/h2Bjuwp3ncDjuKZz4DkcD4cR3OBoI\nJ77D0UA48R2OBsKJ73A0EE58h6OBcOI7HA2EE9/haCCc+A5HA+HEdzgaCCe+w9FAOPEdjgbCie9w\nNBBOfIejgXDiOxwNhBPf4WggnPgORwPhxHc4GggnvsPRQDjxHY4GwonvcDQQTnyHo4Fw4jscDYQT\n3+FoIJz4DkcD4cR3OBoIJ77D0UA48R2OBsKJ73A0EE58h6OBaN/mySGE1wA8BXAJYBpjfOsqLsrh\ncNwtbkV8XBH+7THGN1ZxMQ6HYz24raofVvAaDodjzbgtaSOAL4UQXg0hvH8VF+RwOO4et1X13xZj\n/G4I4R/gagH4Rozxy6u4MIfDcXe4lcSPMX73+vh9AJ8D4MY9h+Me4MbEDyEchBB61/NDAD8N4Our\nujCHw3F3uI2q/wjA50II8fp1fjvG+MXVXJbD4bhLhBjj3b7B1cLgcDg2gBhjsM67K87haCCc+A5H\nA+HEdzgaiNv68R0bQAghG9bjZaHtPPw6Ra8pzys66nOOesCJf88QQsDOzg5arRZ2dnYW5mXkt4io\nz8ki0mq1cotKCCEj8+Xl5cKcjzL0Y0c94MS/ZxBC7u7uot1uLxxbrfLdmxBWS+QYY470MvixEHk+\nn2dk1nNr8Hs4Ng8n/j2DSPx2u429vT10Oh10Op1svrOzs/AcTTYmPUtuIb5oEEJ21ipijJjP55jN\nZhmp9VzGdDrNNBB5nqMecOLfMwjxd3d30el0sL+/n41ut2sSn5FSz2Uur8+j3W5n8xhjRmpNcjlO\np1NMJpMF0stWwbF5OPHvGZj4e3t72N/fx8HBQTZ2d3ez/7VIZu3FeR5CQLvdzoYQX0aMMSO2kJwf\nTyaTnK1BXlu2DI56wIl/zyCqeLvdRqfTQbfbxcHBAXq9Hnq9Xo74FtjQZg15bbEZaDtCjBEXFxeY\nTCYL4+LiwiT9bDarZHtwrA9O/HsGS9UX4h8dHWFvby/735TELzLMieGQR6fTyeaXl5e4uLgwBxsX\n2RYgNgKX+PXBvSR+yofN5/h/rXP6/G384OvE3t4ejo+PcXx8jKOjo4V5p9MpfD5Ld2sBCCHkiK7J\nbxH//Pw8m7PBkYe8zmw2A2AbHOVYZIfwuIDV4N4RX1ud9ZHdT7wg6PPsrtKuqzqj0+lkar01Op1O\nISm0X53Jb6n6QliZX15e5lR7PZeFQI/xeIzz8/Mc8VNkZ8MhGw1ns1m2CFiv4aiOe0l8NjjxXlSM\nUXoh4KEt1tpqfR+IL4a8w8PDhflNjHv8WBv39HdrGffYsCfk10POz2YzU4rLmE6nC1qEzGXhsBaM\n1Od12LjXxLdUSiZxiuRW4MsyATCbxO7ubua663a72VyO7bb9kzIprEg7Tfyq7jwhv3bl8ULAj5n4\n1vtPJhMMh0OMRqPsKC7K+Xy+oB1Yn89RjntJfDFAsR9bXFtaA9BuKXme7Dv1PrTMD75pyIK3t7dn\njqp+/JTU5a2UtZ1io50M/dhaEOSotxb68fn5Ofr9Ps7OznIBSfP5HJPJJPt/IbqQ32MElsO9Iz6A\nnMRn6XdwcIC9vT1zbyrzItLIc+uMVqtVaHwr01hSe2tN/NRgr0AqPDcV2SdHJrz8j8xHoxG63a5J\nejEOhhBy0l40FUd11PsuN6D92Ht7e+h2uzg8PMTh4SG63W6OCFqyi2bA0W7LRL5tGvLZWQXnYxUC\nlBnH2DCq59o2oO0ERRK9yoIxGAxM0o/H4+xz8ufQ3hqX+tVwL4mf8mP3ej0cHBzkYtd5LqQX7UCO\nPK+7xGeJbEnnZWBl6Ml7WC5T/t/USBntZKS0ADmenZ2ZpN/f31+wwejEIkd11PIuT6WEtlot7O3t\nZdL96Ogo81/Lsdvt5ohuET9F+vtAfGAxdmHZWIQqUrEsJ9/SFqocReJbxJdgH/YMiCtwPB5jNBoB\ngGlPYKPhMp+zqajdXS5GpJRxrtvtZoTXxD86Osr2hykjHqv6e3t72d5fXHl1lxwpki9z7Vp6F/29\n7HVE4qaOGq1WK4sXiDHmVHcJHtrf388W9ouLC0yn04zQBwcHCy5CGcAzyz9/Nl6kHFeoHfHFnaSl\ntcw5PFUGPxaXljZ+sUVfyC+vLdb8+xDAs+qIQ70I6Ncqe+0yslvnWF3XGp3kHxweHuL8/DzzBMjz\nut1uTgMYj8fZ4iGLg95e8LU4rlBb4ssNoIdIAtnTM/F7vV62F0wNrQmwxL+vxOfjKl479Vj/TYik\nSZ+S9mKNt4jfarUwn89zEp8lvbhwu90uBoMBBoNBzv06n8+z/9exAQIn/jPUjvhitRZrvRD88PCw\nMFRVxv7+fmF0XiqAR1T9ugfwCFJ78KoLQBkJqryORf6y5xZJeyF/t9tdkPSchizxGizpJeJPPAf8\nGdnv77hC7YjPEl/UeklEkb18ajE4PDzMglh09RiepyLT7oPEZyyrlt/0f8teJ0X4on2+SH92E4qE\n3t/fz5GeBQH7+OU1ptMpzs/PF2w1UvyDhy8AV6gt8VniHx8f4/T0FKenpzg+Ps4IL9Z9XgQ6nU4y\nKacsOOW+ER9YHYFXdQ3aLZj6f701sEJxueCICAHR6IBn6v35+TlGoxF2d3cxmUwWrsXJvojaEV+v\n8IeHhzg5OcHp6Smef/55nJycLBCex+7ubtLFZc1XZSRzXKGKMRBIp+XKVoDV+263m8X87+/vZ9Jc\n1PvRaJRFXeoAH/fz26gd8SVAh8l/cHCAo6MjnJycZMS3MtR0dtqyWIdksKzMRcc6uqRSC2nR38qM\nkfxYFm927e7t7WE6nQKAmfIrA4CZzgsgp03U5bvcFGpHfCDvy5dVn/d48piz8VhNt1S8lIRZN6wI\nNz0vGpu+Ya1tk56nUqL1VqpoEWDi82dmd5/l5+92u2ZasGgS2s/f1O1A7YivV3pxvelUVHHHMfEZ\n2o9r+XXl/DqhiWzFthcluWz6BhVi89B1Dth4qvMJUnYUrR2wQVYTX9x9kt/PLr9ut4vRaJT5+FNp\nvUCz8/lrSXxW97UbhyV+ygdfFj8u/yNY5w+uk1SY4PJY57fzY/ZLbwJigymLldBBVIzUnluTX0f1\nhRAyzU8kvXb5sZ+/3+/nJD37+Zvu4y8lfgjhkwB+BsDjGOObr8+dAvhdAC8DeA3Au2KMT1d1UVrV\n5yw8kfY6h15LEkt1rgP5rdx1HXduVbCV8NQ6EF8X4NTpwTI4d563CCzVUwuA1uA4yEf8/Gz9FzsA\nh2Jr0ksFH8/nrybxPwXg1wF8hs59CMAfxxg/GkL4IIBfvT53a1iqPmfVSdotF9xIET+1T5a/W8e7\nhtyEqcF166zjprvR7OzsLGQ98pDfignG2wMmdSqKjxcGOc+ReNrPzy4/Du6JMeZIz37+pufzlxI/\nxvjlEMLL6vQ7Afz49fzTAP4Ed0B8liJM/NTeka45O1p7afnbJsgvN2KRVBcLtbZYj8fjzEK9KbTb\n7UyqsoSVI1fZARZrJLK7DkjnB0hQj0hiHeQD5P38YvBL+flT7j5tbGyK1L/pHv9NMcbHABBjfD2E\n8KYVXlOpVV9H4hWp+hb5U26ydfzos9lsoSotZ5uJQUqG1J2TIS6tTYFr/llHLem19sbEZTJrAmoS\nLuPnF0k/mUxwfn6O4XCYEd/z+a+wKuPeShnDRNVFHMU1U1YayqoHp4mfsvzfJebzuVl9VkbdiS+p\n0RcXF9jf388dhYC6rx6X15KQ6pQHIBVQVdXPH2PMtKPhcIjhcJhVZup2u7nrslzATcFNif84hPAo\nxvg4hPACgO+t6oIuL69aLslK3e/38cYbb2Qx2uKeYRcSz2OMyUKP2qqbWgDuEiLxU+q+FZRSN1Vf\nfiN9zVIvTxavg4MDDIfDXLETbZxl2wCATBUvCvgp8/PrSkvi85dCHvzd85aDffzbjqrED9dD8AUA\n7wPwEQDvBfD5VV0QZ1oNh0OcnZ1lN0ur1cJwOCz0F8cYc8TSR6tE8zqJX8W4Zxn2ZF4H4jPpLy4u\ncoa+/f39bAHgIqg6vZptNt1uFwByxjxL/daGvyLic9SnhHdLZB+3+5IthST0NAVV3HmfBfB2AM+H\nEP4GwCsAfg3A74cQfgHAtwG8a1UXJBJbJP7Z2VnOSjscDpPVedrtq26uqQ4vXNfdIv06XGUiLbU6\nrN15qcaUm7bqt1qt3DVarjy97+c510fkhVj27KmSa4wiP782BgvxxVgaY8zt9YX0Yu1vCqpY9d+T\n+NNPrfhaAORV/dFohLOzs+xHms1m6Pf7ydLZ3NutrBNLKmT2rqV+1QAeq1FFXQJ4JpNJMnjH6nXA\nAVhCQl6E2VDHhlomJ5BX+1N+fkvV7/V62UIq78eSfjqd3svMzNugdpF7WuKzwU4MSDp4RHdz1f3a\neC4GIKtSyzqIL+9V1LG2rCb9JqG9KXqwF4ZzKmR+dHRkSvq9vb3sM8p5eT+2+pf5+TnSU1x8bEgV\nnz2TfjKZ1L6s+qpRO+LrPT67ZkajUdI4xN1c2RgmMdsyRGoy4TX57xIp+4K+nlRM/6aNT7y/tmoc\npFqbyQIwHA4XJL1oAhx3L++lja9MesvPr3M7mPTsauS0Xg7saQpqSXxR9WOMmSFJcq61FNFH6cZi\njeFwmCO+RbZ1ESsVPGS5F9cZZ1AFRSm4EtmnNTGZj0ajBUkvlXNF4vP7WEE1RX7++Xyek/hiG9Fd\nfLg5Jxv6moLaEZ9XY+DZnlis3SnCVyG++MGLiO+4HcT4p5N05DGAzMgno9frYTgcZt1y2GAbY8yF\n+qZ8+wLdbEU8OmxHYe8Jp3Y78TcMHW1nubBSQT6s6ouKx73VrYSdukjSbQFvX7SbjMOSRQvr9/uZ\n1f/y8tJsZqqt+ClwiDAnd7G05+483HPQib9hMKm1P1ffVLPZDLu7u5nqFmPMWfQ5fTMVuSev67g9\n+PdZhvhCQknCkUQcjsuv8huJZsAeBg7Mmc/nuTBelvhNQu2Ir41fsufTKvl8Ps+CSabTaU411L5v\nLfE3EbHXJFhxEXKOsw9HoxEGg0GuvoJ4dTTp5W9lEIkvWoOQntN6JapQFhvf49cEqZtGq/eWO0lu\nHN2jnV1FTvq7hRUMJefEVSsSn9VtTqXVpK8aTqslvjxHzs1mMwwGg1yPRd/j1wCWtBDCy4rN7iNd\n301uHMsfri33liXdcTtYkZDy24UQFiQ+l1CT389Ku12G+Kz9AcgtBBIExkVdXOLXBNqvbVVv0ef4\nh9NBMZa7znIFOVYD/t1EzZbHvMfXpGf3IJNeVP+qv5M8l6X/7u5upvlJZWatbTjxNwwO1gCubgTZ\n65dlbfHzi+aOu4P+/YBnv02r1cqIz2XT5HnAYoGNZYjPZJcjCwIhvlb1dQjwtqOWxBe4xf1+IxVg\nYyUkdTqdXBYiG2WXCVXWobyyfRD7AXdI1mXbmiTxm7XMORwOAE58h6ORcOI7HA2EE9/haCCc+A5H\nA+HEdzgaCCe+w9FA1NqP77if0BGW7CPnQio69Va3ReNw7Nv62DmK0KrUy+8JbK7F2rrgxHesFBJu\nm2qjvb+/n1XZlbLX/FhCaXU47bKRdUWVezieX7dpk9RuHTZuJR7dZzjxHSsFx9lb1ZClvp4QnYdU\n5OFw2lQ35KrXAuSlte7AoxuzSmNSXU9Ajtsi+Z34jpVCJ9hwhV3d5MI6auJzs82bqvs6Z8Bqw87X\nyZmdIYRcSfZtgRPfsVJo4uuOOUJ8Pfi81OK/japfdH289RDis8SXOvtS91FnG24DnPiOlUITX2rb\nszpf1F5LHkufe51Ic5vrkqOW+LoXgG6mKfUEtglOfMdKoUtfCfGPjo6yfb3VYptbbKUk/k33+EC+\nG4+1x2fjnia9VfvxvsOJ71gpUhL/6OgIx8fHODw8zKz21pBFQKfPrtKqz80/WNWXAeRJv41FOpz4\nWwCr4IXlQy87p1/rJtjf38fJyQmOj49xcnKyMA4PD3MkE+nOj1nir0LVZwkuCxOX3pba/icnJ4gx\nYjweZ2TnWoHbRH4n/j2E1cFG+6h1jztdnzB17rY3t/TH43F8fJzNWZrr9loseW9Depb2HLgDYKGD\nD/fyA67abA8GA/T7/ez7uLy8xGQyceI7Ng+r7iAHpsjgaLgq47ZGrE6nk/PR67kY7VIttnRD1NtI\nfCY9S3uOJ5CyXsCz9l+dTidHeqkMvE0GPif+PYTeq/ICkGpayaGxRfNVEJ+t89pVx/t2XpisIxP/\nNmo+k1836rRI3263F0gv57YFpcQPIXwSwM8AeBxjfPP1uVcAvB/A967/7cMxxj+6s6t0ZNCk14PD\nT60e9al9tczb7dvJgna7nXsfHqLCc2w8x8jzOY7Zv0m8fkrdZ+JLAU/WAqS/H5N+OBw2j/gAPgXg\n1wF8Rp3/WIzxY6u/JEcVWIkmYqnmwBnLT24F1ci4LfFZclqDyVx0tOY3+Y6Y/AByxOfrFQ1A2ngx\n6WVBbJSqH2P8cgjhZeNP27P83TNYpNeRaOIT1/HwqVBZOYrEuymEWCk7A3e+1dsUPupzN/Wja1++\nfEd8rfv7+1nXJenDKKQ/ODjI2ns1TeKn8IEQwr8G8D8B/PsY49MVXZOjBKnUUu4SK1JdfOgSQCNH\nPeT8Kohf5jWw3IdVz90G8n3JdkN663FCzu7ubkb6s7OzjPhNVPUt/AaA/xBjjCGE/wjgYwD+zeou\na/thueJkzkd9TtT5lETtdrsLRNdDk50f35b42tuQ6nZU9Pzbvn+V/2HNg9Nurbr7vGBtC25E/Bjj\n9+nhJwD84WouZ/thqbR6pFx1IjUtd5iMbreby3W3jqLa60AZef/bfr5UkFAdoJuvisSX+Wg0ypp6\n6IYe25KgA1QnfgDt6UMIL8QYX79++LMAvr7qC9tmaNXcKlyRagzK+eNWEAzv7VNZcDxk/7oq4gM2\n+esCIb4QWrr6yBiPx2Y3n20iPVDNnfdZAG8H8HwI4W8AvALgJ0IIbwFwCeA1AL94h9e4VbAkN/ut\nrdbf2niXcs1ZMe96zq41ec4qW0VbkYR1WwSko7IY9KSV13Q6zRG/0RI/xvge4/Sn7uBaGgHep3MA\nDQfSWL5sziTT2W16noqD53BY/d6rlvhyrAvZBZx8M5vNMJlMsv59k8kkp+pPJpPmEt+xenBaKMen\ns/TV2oAcJcY8FR2ntwCa4EUhvKsqamkd6wImvkj7i4uLrGGnSHxZECSkd5uq7wBO/LXDkvgstWXP\nrWPX5SiBJpYfXjLfLGu/tlKnAmdWRVTLK1EXaIkvxB+Px67qO+4Geo+v00NF6uuMNZmL1V5XqZX5\n3t6eaRtggqf23nVUzVcNLfE18YtU/W2CE/8WSPnatQuOH4uqXlRoUhPeIr5208lcSkelRhXcRrJJ\naerUqIKi70/+XvTcKtco7rvZbJZbAFjF19LeJX7DkbJYS2CIlWwiQ+/R9Vwb3/RR3HVcm87KXa8i\nvflGrjKvAvaJM7lkXtagIoSQTNzhmP2b2hL0QsQ+fXHpcTTfNpIecOLfCKkgnBBCTn23jkUJMtqv\nbrn7tFU/VbSizI3GN/OyxyJoNxm7yjj3na+D5zrJR6cOp8J+udhGGSzSW4PJv21w4i8JVkGtAJtO\np1NaSVb72/kx15K3hq4ImypKWUR+TXqtihfNyyAGM9kny/5Z5rPZbOG1+PUl7Ji/EyGe9dm0BlAF\nKeKzxNcqvkt8x0IILauiYqizEmG4RVQqT74siIfDc1kisjuuatBM2X68aEFIgd1jo9EoM5jJkaPg\nrKMsnGL7kO2BeEJ0SDOXvl4F+S1pv43kd+LfAEx6vZ+XPbwUb5Sik3KUfbwltUXNLwrZTdkO2Hpv\nWeo1KfQ+d9lFIIXZbIaLiwuMx2MMh0MMh0MMBoPsOJlMsvfn65D53t4eer0eptNpdl1cYIS/CyH9\nbdT8Mom/bW48gRN/SWhVnxszCPElQ+7k5ASnp6e50ev1SgtVaBuCtb2wFgSL9BZSaj4vAHoxqEoA\n2dML8fv9Ps7OzrKjNKXk9+e55Mazei/bG+1WE9IvK435M+kkHYv02ybtASf+jcAWfJbAHFknEv/0\n9BQPHz7MhhA/VXByZ2cnew99TLkMrb+XIWXdTi0AVa3bLPFHoxH6/T6ePn2KJ0+e4OnTpzg/P09u\nIWKM6Ha7C+q9GDRFGvPvoF9n2c9eVeI78RuAInddKsZehq4n/+DBg9yQYhcpy732tVsquhyr7sG1\nIU0Xn2C1V+9trQWhCOfn53j69GlGdj24DbV1/ZPJZKGYiA6dld9C5qnPaoEJL0RnP77OymM35DaR\n34mvwJLcSp1NdYGV0ev18Nxzz+G5557DgwcPcHR0lLWNYlddak8OFPvRU8Tlc/J/1oLAPmvL355a\nBKrud8/PzzO1nke/38dgMDBVff344OCgMFFGk7AKKfXn13H6o9EoG+PxOFsEPFa/IRDiW0UuOCXW\nqiQrxH/w4EEm8aVtlETkaas9J8ZoEliwcsh5sHSyhvV8kW5MMGtB4QCcFCaTSc6Yp+dlxj0AuUSZ\nVARd1b23tUDoiD0J1x0Ohxnx+f09Vr8BYHXeSm8tynXXNe5kSLUbIb42zLHET0l7lljiK5cbV4eZ\nWntzJq8OsOGhya+r1JTd/NPpNCc59XE6nS4QXe/RdaKMkO+mpOf/K0rQGY1GGA6HOeLLgujE33KI\nxJdMOCsIxwq15bnOmOMYfM57Z+ILLLLzkaWVkIOPZeo656CnFo9UJFsVlVeMe9a1cQCP9fmAK0u9\nqNpyTUWqfpldo+w7ZOKzxOe9vqv6DQBnznEwjlWzLpVok4rK42qtZZF1+mhJfLGea4maMt7pjDQ9\ntGptHcuk3nw+z4Xo6jnbIPTnle+/LDU2ZRjUsL5HawG09vh6q+ESf8vBe3xxzR0eHuL4+BjHx8el\nhSx5L29Z/bW7judFhNf7U33DSrCMNIC01HQhvhSdYGksg/f7vO9nlbcIZUk61vOZUDs7O4XE50i9\nFBFTWpO1x9cSfzgc5kKMfY/fEFiqfq/Xy0XgpUpUHx0dYX9/38wq4yQaS0qlSK/Jf3l5mZPacsNK\nh1dRp1PEk+AaIZee877WWgTKiG9J5JQv3CJSu91eqIJzG1VfXxPv8TXxZRG1NCBX9bccnFrL5Jeg\nHF2vXp+TxpO6G4zMWd20jG+aKPrcxcVF5hqzjjchPi8ATHzL+r8qqWdpPOKb1wuFHK3Q4yq5CPqc\nNnLyIpoqu+USvwFg8lslsjgjTrdy1gTnQBOZp/bPlnqujxcXFznVnodIq5Saz6q+Nrwx4VOhq6tC\nqndAq9VayDi0mmdqb0iVugOW1OctjLZJWFl62wQnvoKOw+f8eisV1ro5tWouc+BZvnrKAKaNa3ph\nsAx6PMSAlgryYcOgrjBr3fCrDlnVmY0694CrDaW+35uQX2CRn38HrfHoLca2wIlvwJL4OnCHC2Do\nm9JS4+U4m81yxiOds84E1IsBB5ykXGac1ZZy56UWHN7P3mWsuhUdKd93kcS3oh2XIb1Afx/axckL\n7Taq+YATfwEpia+lvqXqc3UYvrlY4vIe2xpCXr4RrZH6H5ZQlv2gSuRfKlR3FTe/ldmoF1hdciwl\n8ZdJTCpS9/VCaG233LjXAOib0pL4Vp16uTFZvdd7SZ2rrkeqcg27l1IWd5b2Kat6KiIvpd7fhbTT\n9Qx0SHTRwppS9VPQCxYvhKk9/l0ufHWBE19B70G1xF/WuKfVa/YZ9/v9nEW+3+9n5Z1F+uuh9/Ap\nyZRyexV5EpYNkLnp92uR3iolbi2qVcuLpa6Zffma+KI1pRbObYIT30CRxGeJpPf4Epwj0MEi4jcW\nq7xksUka69nZGQaDwYLhjufiUkuRusxXnooXsP6Weo3bQpNfb6WqGPe0R0DD+gxyjiW+pepb34MT\nvwHQN4aWCFaFXbmRxdeeGsPhMEd0mVclPse630dojUqTvyrprUIkgiLtpijGQUYT4MRXkJtDJHO/\n38+KYLZaLVxcXCxUzJX5xcUFAJjBMazis2rP6r7ODOPMtG1SN1MGPt7rp/b1RZWHgHRNPR20w5GI\n27iHL4MTXyHGmDPCDQaDXGWci4uLhWw8keYHBwcAkAXTpIYOuuHH4ovXRSi26aa0pL5lxbfIX8WN\nZxkxOXKRF9RtW1SrwomvwMQfjUY50s/nc5yfn2fptmx1F5LGGBcqy/Kcs78sd55Y7lNx6vcdKVWf\nIyTL9vX8OpbE19KePR8cJ7Ft3+0yKCV+COElAJ8B8AjAJYBPxBj/UwjhFMDvAngZwGsA3hVjfHqH\n17oWSBKMEJ9JLz74Xq+XyyDTklmr8Tw4CUSnxPJrWTfntoBVfe3Ht1T9VNESK94fyEt8/i6tkFzt\nsmsKqkj8GYBfiTF+NYTQA/AXIYQvAvh5AH8cY/xoCOGDAH4VwIfu8FrXApb4Fuk14a2bSIx21nE0\nGpmReTpc10pn3ZYbU8jLEl+Tvqg2YVnQDrvstKS3JH7T9vdABeLHGF8H8Pr1fBBC+AaAlwC8E8CP\nX//bpwHaAcN3AAANEklEQVT8CbaA+Gzck5tHwmQ7nc5CG2VtfLu8vDSry8oYj8fm3lMH0KSCSO47\nWNXX6r4mfyo+X78eI5WIw9un1B5/G77fqlhqjx9C+FEAbwHwZwAexRgfA1eLQwjhTSu/ug1AJD7w\nLKFmPB5nN6IUu7AkvTznyZMneOONN/DDH/5w4Tgej80gmZRvXs+3AWVWfSa9tc8vg6Xq69wE3+NX\nxLWa/wcAfvla8utvaiu+OZHycvPMZrPcjTefzwuzwi4vL3MNJETFlxLT5+fnG/pk9YAl7a1qRSnj\nXhksFV8X2+CaelULjGwbKhE/hNDGFel/K8b4+evTj0MIj2KMj0MILwD43l1d5KbAaqOAc9q5bTPw\nLPDn6dOnmQWfc92bdnOlIOTXIbtWVCTv8VNgac3JULqyzmg0yn4bzovYRpdpGapK/N8E8Jcxxo/T\nuS8AeB+AjwB4L4DPG8+7d7DitBksRaRiLvBsQRCrPhOfy0M3HZYrz0qCYrU/FZprhdRyboQuTTYY\nDDLNSyQ/22ma9PtUcee9DcDPAfhaCOEruFLpP4wrwv9eCOEXAHwbwLvu8kLXDR3bLedEmoikl3Oy\nhxQ/vkgYkfhNu7GKoCV+KlZfpzszLNLz9kzXJBR3qoRFs8TnrMamoIpV/08B7CT+/FOrvZx6gAkv\nEv3y8qp8lkgTPs9Vb2OMZkadBPc0HVUkPsfql+3xtRGUJb4OkxabCwdScSXdJv0+HrlXALmRtJqp\nJf3FxUV2owJYKJjRxBurCGUSn3sMitTXATpy1PMiic9GVg6P9j2+A4Cd0mlZ7+UG4wgzAMlCmk26\nsVJISfwiVb9KxyHtvxeJzynQnAHJ8RhNXJid+AnonGy23M/n84V8cNYKdEGLJgaIFMEqdJJS9dm4\np2HFQBRJfFH1dVdcJ74jCcuY1JTc7WVh9RSQx9xUlFuSScajtuyz1BfypxZV3t+nGmJy6jOXMnPj\nnsNxC7RarZzE1u3Ge70eTk9P8dxzz+H09DQb0qFI2pDpKsbcNktn4HHOva5cLENnQOouOU2LsXDi\nO1aKVquF3d3dXLESHr1eDycnJwtD+hJy01FZNCyJX5Rvr8mvC6LotuJNTNRx4jtWCpH43W7XbDHG\n7cf06PV6OWnP6j5H7llJOEJgVvEtia+rG21j2nMVOPEdKwVLfFHrHzx4kA1R56ULsZ4L2S1fvrhR\nWdXnKrmSVclS3yJ/qpeAS3yH44bQEv/Bgwd4+PAhnn/+eTx8+BDHx8dZnUJR6bl2obQS1+W3rLLl\nukouG/V0hyGW+FYqdJNIDzjxHSuGSPyDg4Mc8R89eoRHjx7h5ORkIROP6+mLWs/+e07S0f56XRff\nak2mpb42DrJ3oClw4jtWCi3xT09P8fDhQ7zwwgt48cUXcXx8nJPmehQ1y0gZ93ShDYv4LPF1jEbT\nDHuAE9+xYkhJLYm/73a7me9eLPi6K46uq2e9pkBH52mprjsIc01DsQM4nPiOOwJLaavfnT7Kcyzo\nfHsdmafz7SUWv8khuWVw4jtWDt3sooz8RTXygTTxdfadZOBZ2XdN28OXwYnvuBNowqfIX0T8KoU2\nOAlHMvA4+66pFXbKkK5n5HDcACmjnCZ9WbnsmxTakCQcVvWbWmGnDE58x50hVUq7aH+fqrSj3Xha\n1bfSbpucfVcGV/UdK4eW9FaWnqXml5FeZ+ClJD43IHXi23DiO+4EZYY9ywBooSjfXtx3XEjT8+2r\nwYnvWBpFxNVFNMp631lSvqibkHbfSY69tB73fPtqcOI7lgJXz7GOnFMvBTWsunkCKWumrfZ6CIEH\ng0HWrET286zae759NTjxHUtBIvN0l1uZS1UdIT7n1Bft5wHbas+FSyeTCc7OznLEFykvJc09374a\nnPiOpcAVcq1kG0675cSblMQH7AAdHWcvc4v4bMX3fPtqcOI7lgLH4nc6nUydl6NW9VNVdFLQxjuR\n5HJMEV/+7vn21eDEdywNUfUlnVYKZUrxDZH4QvyyPT6DiS+GPCG3ROZZqj5LfM+3L4cT37EUtKov\nBTSkgk5K4rNFX6fF8vzy8jJLsRWJLzH44q7jLsRs3JM9vufbl8OJ71gKbNzTxO/1ejnj3rJ7/JSf\nXiT9G2+8sdB2nFV9seh7vn05nPiOpWDt8aVm3vHx8UK1XKmhZ7XBsurjs7TnzDuW9npfz5Z8z7ev\nBie+YylwBxxdaEMTX2roscQvC9CxetpzgI624LPl3lEdTnxHKVhSc7NLseYfHByg1+uZEl/v8a1i\nmTzYhcekF+L3+/2FQB2PzFsepdl5IYSXQgj/LYTwf0MIXwsh/Nvr86+EEL4TQvhf1+Mdd3+5jnVD\ndwkWVV8s+imJf3h4uBC5J5BOw1atPK6PZ4Xk6sy7pna7vS2qSPwZgF+JMX41hNAD8BchhC9d/+1j\nMcaP3d3lOTYJTXrAVvW1xJdzRRJfF8oUlV1Ley31B4PBQhtyl/jLo5T4McbXAbx+PR+EEL4B4MXr\nPxdHYzjuLSzSi8RnVZ8t+tIKS3e+Te3xmfRC5JSqzxZ8ITsPJ/5yWKoQRwjhRwG8BcD/uD71gRDC\nV0MI/zmEcLLia3PUADq2Xkv8/f39pHGPrfq6Lj5L/GVU/X6/n1T1HdVRmfjXav4fAPjlGOMAwG8A\n+McxxrfgSiNwlX/LYFXHscpnlxn3tB/fan9ltbW2jHvss2ervkv85VDJqh9CaOOK9L8VY/w8AMQY\nv0//8gkAf7j6y3PUBVUq5+roPJHCQvKdnR3M5/Nc0o3ucpOKv5f8+slkssmvYWtQ1Z33mwD+Msb4\ncTkRQnjhev8PAD8L4OurvjhHfcB581ZDC5HSnH5rleCazWYLbav5eHZ2hh/84Ad48uRJptZLpVzP\nsFsdSokfQngbgJ8D8LUQwlcARAAfBvCeEMJbAFwCeA3AL97hdTpqAl33TkfZlWXfTafTXDsr7noz\nHo/R7/fx5MmTHPFFpXdVfnWoYtX/UwA7xp/+aPWX46g72AfPRjmR+PI/HIbLQ7Lu2IDHj9mIJ5l3\nIvGd+KuDR+45khD1Xp+zVH0xxHFUHofiyuPJZJKRnYti8lH29jJc1V89nPiOUugFoEjVZzeddZTu\nN6khhj7d495V/dXCie+ojFRtezbusYtOXG18FO1AS3aZc2VcHajjxF8dnPiOpcDBN5bElzBaHVbL\nkXlcHFPPJ5NJLrqPbQWu6q8OTnzHUhDiM+lHo1EWqNNutxcq4/Jge4BW84fDoefTrwlOfEch2H8f\nQljoXSe+ewnJ3dnZydR8jsOXuXgArNr3jvXBie8wwQY9HbzD+/V2u53933w+R7vdNvfoMpcFQ8fZ\ne8jteuHEd1QCk18ILJJeFoTpdIqdnZ2cJV/PpWY+7/+d+OuHE9+RhHbj6TbVLOmF0K1Wa6G0NT/W\nVn9X9TcDJ76jECKFWe2fzWY51V/27p1OJ7MDpEbKz+8Sf71w4jsqQTe15P2+dMTlYhupsN2iRcGJ\nvz6Eu/6yQwj+a24ZONtOD4ZV316OqbljtYgxmllTTnyHY4uRIv5SpbccDsd2wInvcDQQTnyHo4Fw\n4jscDcSdG/ccDkf94BLf4WggnPgORwOxNuKHEN4RQvhmCOFbIYQPrut9qyKE8FoI4X+HEL4SQvjz\nGlzPJ0MIj0MI/4fOnYYQvhhC+KsQwn/dZPeixPXVppGq0ez1312fr8V3uOlmtGvZ44cQWgC+BeAn\nAfw9gFcBvDvG+M07f/OKCCH8PwD/NMb4xqavBQBCCP8cwADAZ2KMb74+9xEAP4gxfvR68TyNMX6o\nRtf3CoB+HRqphhBeAPACN3sF8E4AP48afIcF1/evsIbvcF0S/60A/jrG+O0Y4xTA7+DqQ9YJATXa\n+sQYvwxAL0LvBPDp6/mnAfzLtV4UIXF9QE0aqcYYX48xfvV6PgDwDQAvoSbfYeL61taMdl03+osA\n/pYefwfPPmRdEAF8KYTwagjh/Zu+mATeFGN8DGRdjN+04euxULtGqtTs9c8APKrbd7iJZrS1kXA1\nwNtijP8EwL8A8EvXqmzdUTdfbO0aqRrNXvV3ttHvcFPNaNdF/L8D8CP0+KXrc7VBjPG718fvA/gc\nrrYndcPjEMIjINsjfm/D15NDjPH78ZnR6BMA/tkmr8dq9ooafYepZrTr+A7XRfxXAfxYCOHlEEIH\nwLsBfGFN712KEMLB9cqLEMIhgJ9GPZqABuT3e18A8L7r+XsBfF4/Yc3IXd81kQR1aKS60OwV9foO\nzWa09Pc7+w7XFrl37Zb4OK4Wm0/GGH9tLW9cASGEf4QrKR9xVZzktzd9fSGEzwJ4O4DnATwG8AqA\n/wLg9wH8QwDfBvCuGOOTGl3fT+Bqr5o1UpX99Aau720A/juAr+Hqd5Vmr38O4Pew4e+w4PregzV8\nhx6y63A0EG7cczgaCCe+w9FAOPEdjgbCie9wNBBOfIejgXDiOxwNhBPf4WggnPgORwPx/wHVKm4L\nzVUzTgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f2e8004ced0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(first_image, cmap = cm.Greys_r)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "#set up an interactive session\n",
    "sess = tf.InteractiveSession()\n",
    "\n",
    "#set up first the softmax regression model with a single linear layer\n",
    "\n",
    "#create nodes for the input impages and target output classes [these are placeholders]\n",
    "x = tf.placeholder(\"float\", [None, 784])\n",
    "y_ = tf.placeholder(\"float\", [None,10])\n",
    "\n",
    "#now create the variables for the linear model: y = Wx + b\n",
    "#these are initialized as zeros\n",
    "\n",
    "W = tf.Variable(tf.zeros([784,10]))\n",
    "b = tf.Variable(tf.zeros([10]))\n",
    "\n",
    "# initialize all the variables\n",
    "sess.run(tf.initialize_all_variables())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicted Class and Cost Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# set up the regression model and the cross-entroy cost function\n",
    "y = tf.nn.softmax(tf.matmul(x,W)+b)\n",
    "\n",
    "cross_entropy = -tf.reduce_sum(y_*tf.log(y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# set up the training to minimize the cost function and run the training for 1000 steps\n",
    "\n",
    "train_step = tf.train.GradientDescentOptimizer(0.01).minimize(cross_entropy)# run the training for 1000 times\n",
    "\n",
    "for i in range(1000):\n",
    "    batch = mnist.train.next_batch(50)\n",
    "    train_step.run(feed_dict={x: batch[0], y_: batch[1]})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9092\n"
     ]
    }
   ],
   "source": [
    "# check the model by comparing which of predicted (highest probability) are equal to actual labels in the test set\n",
    "\n",
    "correct_prediction = tf.equal(tf.argmax(y,1), tf.argmax(y_, 1))\n",
    "\n",
    "# go ahead and cast this to get the mean accuracy\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
    "\n",
    "print accuracy.eval(feed_dict={x: mnist.test.images, y_: mnist.test.labels})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is 90.92% or 9.08% error. Compare this to error rates on http://rodrigob.github.io/are_we_there_yet/build/classification_datasets_results.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build a Multilayer Convolutional Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Weight Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# want some random slightly non-zero weights to remove symmetry and 0 gradients.\n",
    "# also slightly positive bias to avoid \"dead neurons\". Generate a couple functions to do this.\n",
    "\n",
    "def weight_variable(shape):\n",
    "        initial = tf.truncated_normal(shape, stddev=0.1)\n",
    "        return tf.Variable(initial)\n",
    "    \n",
    "def bias_variable(shape):\n",
    "        initial = tf.constant(0.1, shape=shape)\n",
    "        return tf.Variable(initial)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolution and Pooling\n",
    "\n",
    "In a [convolution](https://www.tensorflow.org/versions/r0.10/api_docs/python/nn.html#convolution), both the input `x` and the filter `W` are given as 4-D tensors. The filter is applied to input image patches of the same size as the filter and strided according to the strides argument. `strides = [1, 1, 1, 1]` applies the filter to a patch at every offset, `strides = [1, 2, 2, 1]` applies the filter to every other image patch in each dimension, etc.\n",
    "\n",
    "In [pooling](https://www.tensorflow.org/versions/r0.10/api_docs/python/nn.html#pooling), `ksize` refers to the window size with which to pool.\n",
    "\n",
    "The `padding` option can be `SAME` or `VALID` (zero-padded)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# choose vanilla versions relative to convolution and pooling operations\n",
    "# i.e. max pooling over 2x2 block\n",
    "\n",
    "def conv2d(x, W):\n",
    "    return tf.nn.conv2d(x, W, strides=[1,1,1,1], padding='SAME')\n",
    "\n",
    "def max_pool_2x2(x):\n",
    "    return tf.nn.max_pool(x, ksize=[1,2,2,1], strides=[1,2,2,1], padding='SAME')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First Convolution Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# first layer: convolution followed by max pooling: 32 features for each 5x5 patch\n",
    "# shape [5, 5, 1, 32]\n",
    "\n",
    "size1 = 16\n",
    "\n",
    "W_conv1 = weight_variable([5,5,1,size1])\n",
    "b_conv1 = bias_variable([size1])\n",
    "\n",
    "# to apply, reshape x to a 4d tensor (second and third dimensions \n",
    "# are image width and height, last dimension is the number of color channels)\n",
    "# the first dimension (-1) denotes the remaining factor.\n",
    "x_image = tf.reshape(x, [-1,28,28,1])\n",
    "\n",
    "# convolve x_image with weight tensor, add bias, apply ReLU fn \n",
    "# (max(x,0)) and max pool\n",
    "h_conv1 = tf.nn.relu(conv2d(x_image, W_conv1) + b_conv1)\n",
    "h_pool1 = max_pool_2x2(h_conv1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Second Convolution Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# to build a deep network stack several layer. 2nd layer will\n",
    "# have 64 features per 5x5 patch\n",
    "\n",
    "size2 = 32\n",
    "\n",
    "W_conv2 = weight_variable([5,5,size1,size2])\n",
    "b_conv2 = bias_variable([size2])\n",
    "\n",
    "h_conv2 = tf.nn.relu(conv2d(h_pool1, W_conv2) + b_conv2)\n",
    "h_pool2 = max_pool_2x2(h_conv2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Densely Connected Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# now that image is reduced to 7x7 (28x28 --> 14x14), we add fully \n",
    "# connected layer with 1024 neurons to process entire image\n",
    "\n",
    "size3 = 256\n",
    "\n",
    "W_fc1 = weight_variable([7*7*size2, size3])\n",
    "b_fc1 = bias_variable([size3])\n",
    "\n",
    "h_pool2_flat = tf.reshape(h_pool2, [-1, 7*7*size2])\n",
    "h_fc1 = tf.nn.relu(tf.matmul(h_pool2_flat, W_fc1) + b_fc1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#apply dropout to reduce overfitting\n",
    "keep_prob = tf.placeholder(\"float\")\n",
    "h_fc1_drop = tf.nn.dropout(h_fc1, keep_prob)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Readout Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# add softmax layer\n",
    "W_fc2 = weight_variable([size3, 10])\n",
    "b_fc2 = bias_variable([10])\n",
    "\n",
    "y_conv=tf.nn.softmax(tf.matmul(h_fc1_drop, W_fc2) + b_fc2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train and Evaluate the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2016-09-05 06:06:06\n",
      "step   500, training accuracy    0.800, test accuracy    0.721\n",
      "step  1000, training accuracy    1.000, test accuracy    0.724\n",
      "step  1500, training accuracy    1.000, test accuracy    0.873\n",
      "step  2000, training accuracy    1.000, test accuracy    0.900\n",
      "step  2500, training accuracy    1.000, test accuracy    0.906\n",
      "step  3000, training accuracy    1.000, test accuracy    0.918\n",
      "step  3500, training accuracy    1.000, test accuracy    0.928\n",
      "step  4000, training accuracy    0.800, test accuracy    0.936\n",
      "step  4500, training accuracy    1.000, test accuracy    0.934\n",
      "step  5000, training accuracy    1.000, test accuracy    0.942\n",
      "step  5500, training accuracy    1.000, test accuracy    0.945\n",
      "step  6000, training accuracy    1.000, test accuracy    0.948\n",
      "step  6500, training accuracy    1.000, test accuracy    0.952\n",
      "step  7000, training accuracy    1.000, test accuracy    0.950\n",
      "step  7500, training accuracy    1.000, test accuracy    0.953\n",
      "step  8000, training accuracy    0.600, test accuracy    0.950\n",
      "step  8500, training accuracy    1.000, test accuracy    0.958\n",
      "step  9000, training accuracy    1.000, test accuracy    0.962\n",
      "step  9500, training accuracy    1.000, test accuracy    0.962\n",
      "step 10000, training accuracy    0.800, test accuracy    0.968\n",
      "step 10500, training accuracy    1.000, test accuracy    0.966\n",
      "step 11000, training accuracy    0.800, test accuracy    0.966\n",
      "step 11500, training accuracy    1.000, test accuracy    0.965\n",
      "step 12000, training accuracy    1.000, test accuracy    0.971\n",
      "step 12500, training accuracy    0.600, test accuracy    0.969\n",
      "step 13000, training accuracy    1.000, test accuracy    0.970\n",
      "step 13500, training accuracy    1.000, test accuracy    0.971\n",
      "step 14000, training accuracy    0.800, test accuracy    0.975\n",
      "step 14500, training accuracy    1.000, test accuracy    0.971\n",
      "step 15000, training accuracy    1.000, test accuracy    0.975\n",
      "step 15500, training accuracy    0.800, test accuracy    0.975\n",
      "step 16000, training accuracy    1.000, test accuracy    0.971\n",
      "step 16500, training accuracy    1.000, test accuracy    0.974\n",
      "step 17000, training accuracy    1.000, test accuracy    0.975\n",
      "step 17500, training accuracy    1.000, test accuracy    0.974\n",
      "step 18000, training accuracy    1.000, test accuracy    0.973\n",
      "step 18500, training accuracy    1.000, test accuracy    0.979\n",
      "step 19000, training accuracy    1.000, test accuracy    0.974\n",
      "step 19500, training accuracy    1.000, test accuracy    0.976\n",
      "2016-09-05 06:16:22"
     ]
    }
   ],
   "source": [
    "# This training takes about 15 minutes on a 3 GHz Intel Core i7 (1 core) and achieves ~97.6% test accuracy\n",
    "#\n",
    "cross_entropy = tf.reduce_mean(-tf.reduce_sum(y_ * tf.log(y_conv), reduction_indices=[1]))\n",
    "train_step = tf.train.AdamOptimizer(1e-4).minimize(cross_entropy)\n",
    "correct_prediction = tf.equal(tf.argmax(y_conv,1), tf.argmax(y_,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
    "sess.run(tf.initialize_all_variables())\n",
    "\n",
    "acc = []\n",
    "num_train = 20000\n",
    "\n",
    "num_test = 2000 # -1 to test all, but use fewer for limited memory situations\n",
    "\n",
    "startTime = time.clock()\n",
    "print time.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "\n",
    "for i in range(num_train):\n",
    "    batch = mnist.train.next_batch(5)\n",
    "    if i%500 == 0 and i != 0:\n",
    "        train_accuracy = accuracy.eval(feed_dict={\n",
    "                x:batch[0], y_: batch[1], keep_prob: 1.0})\n",
    "        test_accuracy = accuracy.eval(feed_dict={\n",
    "                x: mnist.test.images[:num_test], y_: mnist.test.labels[:num_test], keep_prob: 1.0})\n",
    "        print \"step %5d, training accuracy %8.3f, test accuracy %8.3f\"%(i, train_accuracy, test_accuracy)\n",
    "        acc.append(test_accuracy)\n",
    "    train_step.run(feed_dict={x: batch[0], y_: batch[1], keep_prob: 0.5})\n",
    "\n",
    "endTime = time.clock()\n",
    "print time.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "\n",
    "print \"test accuracy %g\"%accuracy.eval(feed_dict={\n",
    "    x: mnist.test.images, y_: mnist.test.labels, keep_prob: 1.0})\n",
    "print \"Time to run: %f s\" % (endTime - startTime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "No module named pandas",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-d35986a64dc4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0macc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSeries\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0macc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mylim\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0.9\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1.01\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: No module named pandas"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "acc = pd.Series(acc)\n",
    "plt.figure()\n",
    "plt.ylim(0.9, 1.01)\n",
    "p=acc.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The final test set accuracy should be approximately 99.2%"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
